{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20211101_HillenbrandAnalysis1_transformers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfTrl8PesQB9oZwzioioYv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessie-johnson/jessie-johnson.github.io/blob/main/20211101_HillenbrandAnalysis1_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8je9PvZUUyUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c1cffe-d872-42d8-c3fa-6713bf2d4d23"
      },
      "source": [
        "#using drive as director\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muGcyIgv4Jxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a03dfad-b7e3-4398-f6ea-a42e5de9c8c4"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSWHxH6Y4r1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4edaeb48-bce8-4dde-ed04-7857009c9db9"
      },
      "source": [
        "#setting current directory to the folder with the .wav files in my drive\n",
        "%cd \"/content/drive/MyDrive/Colab Notebooks/HillenbrandArchive\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/HillenbrandArchive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyWUB68IEgm0"
      },
      "source": [
        "#import libraries\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import Wav2Vec2Tokenizer, Wav2Vec2ForCTC\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "from tensorflow.keras import Sequential\n",
        "import torch\n",
        "import librosa as lb\n",
        "import tensorflow as tf"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPSYKRJgCbWI"
      },
      "source": [
        "\n",
        "\n",
        "# MD=torch.load('wav2vec_small_10m.pt')\n",
        "# M=MD['model']\n",
        "# ex = np.empty(768)\n",
        "# for n in range(768):\n",
        "#     ex[n] = np.min(np.array(M['w2v_encoder.w2v_model.encoder.layers.0.self_attn.k_proj.weight'][n,:]))\n",
        "# plt.plot(ex)\n",
        "# for s in M.keys():\n",
        "#     print(s,M[s].shape)\n",
        "#     # print('')\n",
        "\n",
        "\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained('facebook/wav2vec2-base-960h')\n",
        "model = Wav2Vec2ForCTC.from_pretrained('facebook/wav2vec2-base-960h')\n",
        "waveform, rate = lb.load('m11iy.wav', sr = 16000)\n",
        "input_values = tokenizer(waveform, return_tensors='pt').input_values\n",
        "# import pdb\n",
        "# pdb.set_trace()\n",
        "# # Retrieve logits from the model\n",
        "logits = model(input_values).logits\n",
        "\n",
        "# # Take argmax value and decode into transcription\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "transcription = tokenizer.batch_decode(predicted_ids)\n",
        "\n",
        "# # Print the output\n",
        "print(transcription)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}